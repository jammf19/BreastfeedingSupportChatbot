{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping ethics\n",
    "\n",
    "- The absence of explicit scraping prohibitions in `robots.txt`, Terms of Service, or the Privacy Policy does not automatically grant permission for data extraction. So I directly reached out to La Leche League GB for approval before scraping.\n",
    "By following these guidelines, web scraping activities were conducted in an ethical and legally compliant manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used responsible request rates to prevent server strain, by scraping each information webpage separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "url = \"https://laleche.org.uk/category/breastfeeding-information/page/10/\"\n",
    "\n",
    "# Custom headers to simulate a real browser request (found user-agent string in the browser dev tools)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "# Send a GET request to the website\n",
    "response = requests.get(url, headers = headers)\n",
    "\n",
    "# Parse the content of the page\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the content of an individual post\n",
    "def fetch_post_content(post_url):\n",
    "          responsepost = requests.get(post_url,headers=headers)\n",
    "          soup = BeautifulSoup(responsepost.text, 'html.parser')\n",
    "           # Extract the main content of the post\n",
    "          content_tag = soup.find('div', {'class': 'entry-content'})  \n",
    "          if content_tag:\n",
    "               return content_tag.get_text(strip=True)\n",
    "          else:\n",
    "               return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Locate all posts on the page\n",
    "    \n",
    "posts = soup.find_all('article')  \n",
    "    \n",
    "# Prepare lists to store post titles, URLs, and content\n",
    "post_titles = []\n",
    "post_urls = []\n",
    "post_contents = []\n",
    "\n",
    "    # Step 5: Extract the post titles and URLs\n",
    "for post in posts:\n",
    "    title_tag = post.find('h2')\n",
    "    if title_tag:\n",
    "        post_title = title_tag.get_text(strip=True)\n",
    "        post_titles.append(post_title)\n",
    "        \n",
    "        link_tag = title_tag.find('a')\n",
    "        if link_tag and 'href' in link_tag.attrs:\n",
    "            post_url = link_tag['href']\n",
    "            post_urls.append(post_url)\n",
    "\n",
    "            # Step 6: Fetch the post content\n",
    "            content = fetch_post_content(post_url)\n",
    "            post_contents.append(content if content else \"No content available\")\n",
    "        \n",
    "    # Add a delay between requests to avoid overloading the server (polite scraping)\n",
    "    time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                           Post Title  \\\n",
      "0           My Baby Won’t Breastfeed   \n",
      "1       Jaundice in Healthy Newborns   \n",
      "2    Is My Baby Getting Enough Milk?   \n",
      "3                   Inverted nipples   \n",
      "4             If You Leave Your Baby   \n",
      "5          Dummies and Breastfeeding   \n",
      "6  Caesarean Birth and Breastfeeding   \n",
      "7            Beginning Breastfeeding   \n",
      "8  Antenatal Expression of Colostrum   \n",
      "9            Adjusting to Motherhood   \n",
      "\n",
      "                                                 URL  \\\n",
      "0    https://laleche.org.uk/my-baby-wont-breastfeed/   \n",
      "1                   https://laleche.org.uk/jaundice/   \n",
      "2  https://laleche.org.uk/is-my-baby-getting-enou...   \n",
      "3           https://laleche.org.uk/inverted-nipples/   \n",
      "4     https://laleche.org.uk/if-you-leave-your-baby/   \n",
      "5  https://laleche.org.uk/dummies-and-breastfeeding/   \n",
      "6  https://laleche.org.uk/caesarean-birth-and-bre...   \n",
      "7    https://laleche.org.uk/beginning-breastfeeding/   \n",
      "8  https://laleche.org.uk/antenatal-expression-of...   \n",
      "9    https://laleche.org.uk/adjusting-to-motherhood/   \n",
      "\n",
      "                                             Content  \n",
      "0  This page is about young babies who have never...  \n",
      "1  If your new baby has jaundice, it’s normal to ...  \n",
      "2  How do you tell if your baby is getting enough...  \n",
      "3  The size and shape of nipples and breasts vary...  \n",
      "4  When you and your baby have a satisfying breas...  \n",
      "5  Sucking is a basic instinct that babies are bo...  \n",
      "6  During pregnancy your body is preparing to giv...  \n",
      "7  Breastfeeding is normal and natural but it may...  \n",
      "8  Mothers start to produce colostrum (early milk...  \n",
      "9  Some mothers find  their experience of having ...  >\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "        'Post Title': post_titles,\n",
    "        'URL': post_urls,\n",
    "        'Content': post_contents\n",
    "    })\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Save to a CSV file \n",
    "df.to_csv('breastfeeding_info_links10.csv', index=False)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
